{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb342b03-a726-4bd4-9129-861dc3071429",
   "metadata": {},
   "source": [
    "# GPU enabled Kubeflow notebook\n",
    "In this notebook we demonstrate multi GPU training using tensorflow framework. In the example we use convolutional neural network for image classification trained on cifar10 dataset. Example was tested on [charmed kubeflow](https://charmed-kubeflow.io/). \n",
    "\n",
    "**Important**\n",
    "\n",
    "This example was tested on drivers:\n",
    "```\n",
    "NVIDIA-SMI 515.48.07    Driver Version: 515.48.07    CUDA Version: 11.7\n",
    "```\n",
    "And ```tensorflow-gpu==2.10.0```. Check rest of the requirements in the attatched `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55c408ce-dcf1-493d-82f1-bc646dcb3fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 11:59:37.848678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-10 11:59:38.033333: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-10 11:59:38.858836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-10 11:59:38.859039: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-10 11:59:38.859052: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:4', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:5', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:6', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:7', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libs and setup environment\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "\n",
    "# Set for optimized memory usage\n",
    "# os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
    "# os.environ[\"NCCL_DEBUG\"] = \"WARN\"\n",
    "\n",
    "# Allow to use whole GPU memory\n",
    "# config = tf.compat.v1.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9c9a06c-af1a-429a-af2c-9edd43ca2fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GPU:0', 'GPU:1', 'GPU:2', 'GPU:3', 'GPU:4', 'GPU:5', 'GPU:6', 'GPU:7']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract GPU device names\n",
    "device_type = 'GPU'\n",
    "devices = tf.config.experimental.list_physical_devices(\n",
    "          device_type)\n",
    "devices_names = [d.name.split(\"e:\")[1] for d in devices]\n",
    "devices_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b415917c-a91c-44f1-8452-a3ac22acde28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image recognition dataset for 10 class prediction\n",
    "# https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "# Image has 32x32x3 resolution\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b0934e-e543-4ce4-a216-596b40b4ba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling image values between 0-1\n",
    "X_train_scaled = X_train/255\n",
    "X_test_scaled = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c5e159c-114d-48fe-9b9d-cdad612e018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding labels\n",
    "y_train_encoded = keras.utils.to_categorical(y_train, num_classes = 10, dtype = 'float32')\n",
    "y_test_encoded = keras.utils.to_categorical(y_test, num_classes = 10, dtype = 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00bc97ff-b52c-44ee-8251-90a3a98c0e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    '''\n",
    "    Create simple deep model. 3 hidden layers. \n",
    "    '''\n",
    "    strategy = tf.distribute.MirroredStrategy(\n",
    "           devices=devices_names)\n",
    "    with strategy.scope():\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Flatten(input_shape=(32,32,3)),\n",
    "            keras.layers.Dense(3000, activation='relu'),\n",
    "            keras.layers.Dense(1000, activation='relu'),\n",
    "            keras.layers.Dense(10, activation='sigmoid')    \n",
    "        ])\n",
    "        model.compile(optimizer='SGD',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0afaa789-2a6d-4705-b629-b37f3fab968c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_cnn():\n",
    "    '''\n",
    "    Create More sophisticated model. Using mirrored distributed training strategy\n",
    "    Reading: https://www.tensorflow.org/guide/distributed_training#mirroredstrategy\n",
    "    '''\n",
    "    strategy = tf.distribute.MirroredStrategy(\n",
    "           devices=devices_names)\n",
    "    with strategy.scope():\n",
    "        model = keras.models.Sequential()\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "        model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "        model.add(Dense(10, activation='softmax'))\n",
    "        # compile model\n",
    "        opt = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "133b484a-c72b-4077-9eac-72b6196feb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 11:59:54.833137: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-10 11:59:59.759987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30974 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2022-10-10 11:59:59.761843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30974 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB, pci bus id: 0000:36:00.0, compute capability: 7.0\n",
      "2022-10-10 11:59:59.763496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30974 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB, pci bus id: 0000:39:00.0, compute capability: 7.0\n",
      "2022-10-10 11:59:59.765122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30974 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2022-10-10 11:59:59.766790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:4 with 30974 MB memory:  -> device: 4, name: Tesla V100-SXM3-32GB, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2022-10-10 11:59:59.768354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:5 with 30974 MB memory:  -> device: 5, name: Tesla V100-SXM3-32GB, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2022-10-10 11:59:59.769957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:6 with 30974 MB memory:  -> device: 6, name: Tesla V100-SXM3-32GB, pci bus id: 0000:5c:00.0, compute capability: 7.0\n",
      "2022-10-10 11:59:59.771505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:7 with 30974 MB memory:  -> device: 7, name: Tesla V100-SXM3-32GB, pci bus id: 0000:5e:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3', '/job:localhost/replica:0/task:0/device:GPU:4', '/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:111: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-10 12:00:13.845736: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-10-10 12:00:14.750560: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-10-10 12:00:15.663688: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-10-10 12:00:16.800175: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-10-10 12:00:18.464346: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-10-10 12:00:19.872754: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-10-10 12:00:20.993084: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-10-10 12:00:21.931158: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 40s 22ms/step - loss: 1.7741 - accuracy: 0.3707\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.4543 - accuracy: 0.4843\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 17s 21ms/step - loss: 1.2872 - accuracy: 0.5426\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.1681 - accuracy: 0.5891\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.0789 - accuracy: 0.6240\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 1.0041 - accuracy: 0.6480\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.9437 - accuracy: 0.6712\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.8881 - accuracy: 0.6923\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.8379 - accuracy: 0.7114\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 16s 21ms/step - loss: 0.7950 - accuracy: 0.7254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0590028100>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultiGPU prediction. Run nvidia-smi command in another terminal tab to check GPU ussage\n",
    "model_gpu = get_model_cnn()\n",
    "model_gpu.fit(X_train_scaled, y_train_encoded, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c639d608-f4f0-4063-9ed6-77bf43592bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU only prediction\n",
    "%%timeit -n1 -r1\n",
    "# CPU\n",
    "with tf.device('/CPU:0'):\n",
    "    model_cpu = get_model()\n",
    "    model_cpu.fit(X_train_scaled, y_train_encoded, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4256de-d23a-4f0c-bcc2-1926de1bd2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-06 09:31:07.019013: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-06 09:31:08.332506: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-10-06 09:31:08.332701: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 216 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB, pci bus id: 0000:34:00.0, compute capability: 7.0\n",
      "2022-10-06 09:31:08.334204: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:222] Using CUDA malloc Async allocator for GPU: 1\n",
      "2022-10-06 09:31:08.334270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 342 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB, pci bus id: 0000:36:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "NCCL version 2.12.12+cudaCUDA_MAJOR.CUDA_MINOR\n",
      "\n",
      "test-gpu-notebook-0:10459:10934 [0] bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/include_hdrs/alloc.h:70 NCCL WARN Cuda failure 'out of memory'\n",
      "\n",
      "test-gpu-notebook-0:10459:10934 [0] external/nccl_archive/src/proxy.cc:1040 NCCL WARN [Proxy Service 0] Failed to execute operation SharedInit from rank 0, retcode 1\n",
      "16/16 [==============================] - 4s 8ms/step - loss: 2.2795 - accuracy: 0.1620\n",
      "Epoch 2/10\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.1385 - accuracy: 0.2180\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 2.0454 - accuracy: 0.2780\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.9710 - accuracy: 0.2940\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.8560 - accuracy: 0.3460\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.8398 - accuracy: 0.3660\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.7847 - accuracy: 0.3840\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.7592 - accuracy: 0.3920\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.6965 - accuracy: 0.3960\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.6683 - accuracy: 0.4300\n",
      "7.22 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "# Single GPU example\n",
    "%%timeit -n1 -r1\n",
    "# GPU\n",
    "with tf.device('GPU:0'):\n",
    "    model_gpu = get_model()\n",
    "    model_gpu.fit(X_train_scaled[:500], y_train_encoded[:500], epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b447961d-dbca-4086-a047-0d3b24658265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 18s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.9844909e-03, 2.0822229e-04, 1.4139652e-02, ..., 5.5011438e-04,\n",
       "        7.4595697e-03, 7.5909849e-03],\n",
       "       [7.7995681e-03, 7.6944524e-01, 3.5332184e-06, ..., 9.9429064e-07,\n",
       "        1.8379286e-01, 3.8945921e-02],\n",
       "       [7.0480712e-02, 1.6722994e-01, 2.8469465e-03, ..., 7.3819066e-04,\n",
       "        5.4288960e-01, 2.0992452e-01],\n",
       "       ...,\n",
       "       [8.9241883e-05, 9.0138319e-06, 8.3996855e-02, ..., 4.2369706e-03,\n",
       "        2.7003358e-04, 6.4079111e-05],\n",
       "       [2.8460411e-02, 5.3601044e-01, 1.8379822e-02, ..., 1.3022214e-04,\n",
       "        9.0050288e-03, 2.1574055e-03],\n",
       "       [6.6487199e-05, 5.2376394e-04, 3.0200728e-03, ..., 9.1520762e-01,\n",
       "        3.6907738e-06, 1.1142212e-03]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gpu.predict(np.concatenate([X_test_scaled, X_test_scaled, X_test_scaled, X_test_scaled, X_test_scaled])) # We multiplied the X_test to check GPU usage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('3.9.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "635db5889a8e7f14dda695c20229a76694a8038f010b71edc7a46486e7214d7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
